{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f668f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Obtaining dependency information for wordcloud from https://files.pythonhosted.org/packages/f5/b0/247159f61c5d5d6647171bef84430b7efad4db504f0229674024f3a4f7f2/wordcloud-1.9.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading wordcloud-1.9.3-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordcloud) (1.24.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordcloud) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Downloading wordcloud-1.9.3-cp311-cp311-win_amd64.whl (300 kB)\n",
      "   ---------------------------------------- 0.0/300.2 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/300.2 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/300.2 kB 653.6 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 92.2/300.2 kB 744.7 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 122.9/300.2 kB 717.5 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 122.9/300.2 kB 717.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  297.0/300.2 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 300.2/300.2 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70dbd82b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Obtaining dependency information for pymongo from https://files.pythonhosted.org/packages/c8/1a/1ba5578cc3acc8ef0dfd6eb9385f9c4b0fe3039665af93bcf062c34fcdb6/pymongo-4.6.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pymongo-4.6.1-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Obtaining dependency information for dnspython<3.0.0,>=1.16.0 from https://files.pythonhosted.org/packages/f6/b4/0a9bee52c50f226a3cbfb54263d02bb421c7f2adc136520729c2c689c1e5/dnspython-2.4.2-py3-none-any.whl.metadata\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading pymongo-4.6.1-cp311-cp311-win_amd64.whl (472 kB)\n",
      "   ---------------------------------------- 0.0/472.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/472.7 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/472.7 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 41.0/472.7 kB 653.6 kB/s eta 0:00:01\n",
      "   --- ----------------------------------- 41.0/472.7 kB 653.6 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 71.7/472.7 kB 393.8 kB/s eta 0:00:02\n",
      "   ----- --------------------------------- 71.7/472.7 kB 393.8 kB/s eta 0:00:02\n",
      "   ------- ------------------------------- 92.2/472.7 kB 327.7 kB/s eta 0:00:02\n",
      "   ------- ------------------------------- 92.2/472.7 kB 327.7 kB/s eta 0:00:02\n",
      "   ------- ------------------------------- 92.2/472.7 kB 327.7 kB/s eta 0:00:02\n",
      "   ------- ------------------------------- 92.2/472.7 kB 327.7 kB/s eta 0:00:02\n",
      "   ------- ------------------------------- 92.2/472.7 kB 327.7 kB/s eta 0:00:02\n",
      "   --------- ---------------------------- 112.6/472.7 kB 226.0 kB/s eta 0:00:02\n",
      "   --------- ---------------------------- 112.6/472.7 kB 226.0 kB/s eta 0:00:02\n",
      "   --------- ---------------------------- 112.6/472.7 kB 226.0 kB/s eta 0:00:02\n",
      "   --------- ---------------------------- 112.6/472.7 kB 226.0 kB/s eta 0:00:02\n",
      "   --------- ---------------------------- 122.9/472.7 kB 185.0 kB/s eta 0:00:02\n",
      "   --------- ---------------------------- 122.9/472.7 kB 185.0 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 143.4/472.7 kB 177.5 kB/s eta 0:00:02\n",
      "   ------------ -------------------------- 153.6/472.7 kB 48.0 kB/s eta 0:00:07\n",
      "   ------------ -------------------------- 153.6/472.7 kB 48.0 kB/s eta 0:00:07\n",
      "   ------------ -------------------------- 153.6/472.7 kB 48.0 kB/s eta 0:00:07\n",
      "   ------------ -------------------------- 153.6/472.7 kB 48.0 kB/s eta 0:00:07\n",
      "   -------------- ------------------------ 174.1/472.7 kB 51.9 kB/s eta 0:00:06\n",
      "   -------------- ------------------------ 174.1/472.7 kB 51.9 kB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 194.6/472.7 kB 56.5 kB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 194.6/472.7 kB 56.5 kB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 194.6/472.7 kB 56.5 kB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 204.8/472.7 kB 57.4 kB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 204.8/472.7 kB 57.4 kB/s eta 0:00:05\n",
      "   ------------------ -------------------- 225.3/472.7 kB 61.7 kB/s eta 0:00:05\n",
      "   ------------------ -------------------- 225.3/472.7 kB 61.7 kB/s eta 0:00:05\n",
      "   ------------------ -------------------- 225.3/472.7 kB 61.7 kB/s eta 0:00:05\n",
      "   ------------------ -------------------- 225.3/472.7 kB 61.7 kB/s eta 0:00:05\n",
      "   ------------------ -------------------- 225.3/472.7 kB 61.7 kB/s eta 0:00:05\n",
      "   ------------------ -------------------- 225.3/472.7 kB 61.7 kB/s eta 0:00:05\n",
      "   ------------------- ------------------- 235.5/472.7 kB 59.6 kB/s eta 0:00:04\n",
      "   ------------------- ------------------- 235.5/472.7 kB 59.6 kB/s eta 0:00:04\n",
      "   ------------------- ------------------- 235.5/472.7 kB 59.6 kB/s eta 0:00:04\n",
      "   ------------------- ------------------- 235.5/472.7 kB 59.6 kB/s eta 0:00:04\n",
      "   ------------------- ------------------- 235.5/472.7 kB 59.6 kB/s eta 0:00:04\n",
      "   ------------------- ------------------- 235.5/472.7 kB 59.6 kB/s eta 0:00:04\n",
      "   ------------------- ------------------- 235.5/472.7 kB 59.6 kB/s eta 0:00:04\n",
      "   --------------------- ----------------- 256.0/472.7 kB 60.3 kB/s eta 0:00:04\n",
      "   --------------------- ----------------- 256.0/472.7 kB 60.3 kB/s eta 0:00:04\n",
      "   --------------------- ----------------- 256.0/472.7 kB 60.3 kB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 276.5/472.7 kB 62.9 kB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 276.5/472.7 kB 62.9 kB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 276.5/472.7 kB 62.9 kB/s eta 0:00:04\n",
      "   ----------------------- --------------- 286.7/472.7 kB 63.2 kB/s eta 0:00:03\n",
      "   ----------------------- --------------- 286.7/472.7 kB 63.2 kB/s eta 0:00:03\n",
      "   ----------------------- --------------- 286.7/472.7 kB 63.2 kB/s eta 0:00:03\n",
      "   ----------------------- --------------- 286.7/472.7 kB 63.2 kB/s eta 0:00:03\n",
      "   ----------------------- --------------- 286.7/472.7 kB 63.2 kB/s eta 0:00:03\n",
      "   ----------------------- --------------- 286.7/472.7 kB 63.2 kB/s eta 0:00:03\n",
      "   ----------------------- --------------- 286.7/472.7 kB 63.2 kB/s eta 0:00:03\n",
      "   ------------------------- ------------- 307.2/472.7 kB 63.4 kB/s eta 0:00:03\n",
      "   ------------------------- ------------- 307.2/472.7 kB 63.4 kB/s eta 0:00:03\n",
      "   ------------------------- ------------- 307.2/472.7 kB 63.4 kB/s eta 0:00:03\n",
      "   ------------------------- ------------- 307.2/472.7 kB 63.4 kB/s eta 0:00:03\n",
      "   ------------------------- ------------- 307.2/472.7 kB 63.4 kB/s eta 0:00:03\n",
      "   ------------------------- ------------- 307.2/472.7 kB 63.4 kB/s eta 0:00:03\n",
      "   -------------------------- ------------ 317.4/472.7 kB 62.0 kB/s eta 0:00:03\n",
      "   -------------------------- ------------ 317.4/472.7 kB 62.0 kB/s eta 0:00:03\n",
      "   -------------------------- ------------ 317.4/472.7 kB 62.0 kB/s eta 0:00:03\n",
      "   -------------------------- ------------ 317.4/472.7 kB 62.0 kB/s eta 0:00:03\n",
      "   -------------------------- ------------ 317.4/472.7 kB 62.0 kB/s eta 0:00:03\n",
      "   --------------------------- ----------- 337.9/472.7 kB 63.0 kB/s eta 0:00:03\n",
      "   --------------------------- ----------- 337.9/472.7 kB 63.0 kB/s eta 0:00:03\n",
      "   --------------------------- ----------- 337.9/472.7 kB 63.0 kB/s eta 0:00:03\n",
      "   --------------------------- ----------- 337.9/472.7 kB 63.0 kB/s eta 0:00:03\n",
      "   ----------------------------- --------- 358.4/472.7 kB 64.4 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 358.4/472.7 kB 64.4 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 358.4/472.7 kB 64.4 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 358.4/472.7 kB 64.4 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 358.4/472.7 kB 64.4 kB/s eta 0:00:02\n",
      "   ------------------------------ -------- 368.6/472.7 kB 63.9 kB/s eta 0:00:02\n",
      "   ------------------------------ -------- 368.6/472.7 kB 63.9 kB/s eta 0:00:02\n",
      "   ------------------------------ -------- 368.6/472.7 kB 63.9 kB/s eta 0:00:02\n",
      "   ------------------------------ -------- 368.6/472.7 kB 63.9 kB/s eta 0:00:02\n",
      "   -------------------------------- ------ 389.1/472.7 kB 65.5 kB/s eta 0:00:02\n",
      "   -------------------------------- ------ 399.4/472.7 kB 66.8 kB/s eta 0:00:02\n",
      "   -------------------------------- ------ 399.4/472.7 kB 66.8 kB/s eta 0:00:02\n",
      "   --------------------------------- ----- 409.6/472.7 kB 67.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ----- 409.6/472.7 kB 67.4 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 430.1/472.7 kB 70.0 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 450.6/472.7 kB 72.6 kB/s eta 0:00:01\n",
      "   --------------------------------------  460.8/472.7 kB 73.8 kB/s eta 0:00:01\n",
      "   --------------------------------------  460.8/472.7 kB 73.8 kB/s eta 0:00:01\n",
      "   --------------------------------------- 472.7/472.7 kB 74.6 kB/s eta 0:00:00\n",
      "Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "   ---------------------------------------- 0.0/300.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/300.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/300.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/300.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/300.4 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 30.7/300.4 kB 131.3 kB/s eta 0:00:03\n",
      "   --- ----------------------------------- 30.7/300.4 kB 131.3 kB/s eta 0:00:03\n",
      "   --- ----------------------------------- 30.7/300.4 kB 131.3 kB/s eta 0:00:03\n",
      "   --- ----------------------------------- 30.7/300.4 kB 131.3 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 41.0/300.4 kB 89.6 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 41.0/300.4 kB 89.6 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 41.0/300.4 kB 89.6 kB/s eta 0:00:03\n",
      "   ------- ------------------------------- 61.4/300.4 kB 105.8 kB/s eta 0:00:03\n",
      "   ------- ------------------------------- 61.4/300.4 kB 105.8 kB/s eta 0:00:03\n",
      "   --------- ----------------------------- 71.7/300.4 kB 103.6 kB/s eta 0:00:03\n",
      "   --------- ----------------------------- 71.7/300.4 kB 103.6 kB/s eta 0:00:03\n",
      "   --------- ----------------------------- 71.7/300.4 kB 103.6 kB/s eta 0:00:03\n",
      "   --------- ----------------------------- 71.7/300.4 kB 103.6 kB/s eta 0:00:03\n",
      "   ----------- --------------------------- 92.2/300.4 kB 109.2 kB/s eta 0:00:02\n",
      "   ----------- --------------------------- 92.2/300.4 kB 109.2 kB/s eta 0:00:02\n",
      "   ----------- --------------------------- 92.2/300.4 kB 109.2 kB/s eta 0:00:02\n",
      "   ----------- --------------------------- 92.2/300.4 kB 109.2 kB/s eta 0:00:02\n",
      "   ----------- --------------------------- 92.2/300.4 kB 109.2 kB/s eta 0:00:02\n",
      "   ----------- --------------------------- 92.2/300.4 kB 109.2 kB/s eta 0:00:02\n",
      "   ----------- --------------------------- 92.2/300.4 kB 109.2 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 112.6/300.4 kB 95.0 kB/s eta 0:00:02\n",
      "   --------------- ----------------------- 122.9/300.4 kB 67.4 kB/s eta 0:00:03\n",
      "   --------------- ----------------------- 122.9/300.4 kB 67.4 kB/s eta 0:00:03\n",
      "   --------------- ----------------------- 122.9/300.4 kB 67.4 kB/s eta 0:00:03\n",
      "   ------------------ -------------------- 143.4/300.4 kB 73.5 kB/s eta 0:00:03\n",
      "   ------------------ -------------------- 143.4/300.4 kB 73.5 kB/s eta 0:00:03\n",
      "   ------------------ -------------------- 143.4/300.4 kB 73.5 kB/s eta 0:00:03\n",
      "   ------------------ -------------------- 143.4/300.4 kB 73.5 kB/s eta 0:00:03\n",
      "   ------------------ -------------------- 143.4/300.4 kB 73.5 kB/s eta 0:00:03\n",
      "   ------------------- ------------------- 153.6/300.4 kB 70.0 kB/s eta 0:00:03\n",
      "   ------------------- ------------------- 153.6/300.4 kB 70.0 kB/s eta 0:00:03\n",
      "   ------------------- ------------------- 153.6/300.4 kB 70.0 kB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 174.1/300.4 kB 74.9 kB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 174.1/300.4 kB 74.9 kB/s eta 0:00:02\n",
      "   ------------------------- ------------- 194.6/300.4 kB 80.2 kB/s eta 0:00:02\n",
      "   ------------------------- ------------- 194.6/300.4 kB 80.2 kB/s eta 0:00:02\n",
      "   ------------------------- ------------- 194.6/300.4 kB 80.2 kB/s eta 0:00:02\n",
      "   -------------------------- ------------ 204.8/300.4 kB 80.9 kB/s eta 0:00:02\n",
      "   ----------------------------- --------- 225.3/300.4 kB 87.1 kB/s eta 0:00:01\n",
      "   ----------------------------- --------- 225.3/300.4 kB 87.1 kB/s eta 0:00:01\n",
      "   ----------------------------- --------- 225.3/300.4 kB 87.1 kB/s eta 0:00:01\n",
      "   ------------------------------ -------- 235.5/300.4 kB 87.4 kB/s eta 0:00:01\n",
      "   ------------------------------ -------- 235.5/300.4 kB 87.4 kB/s eta 0:00:01\n",
      "   ------------------------------ -------- 235.5/300.4 kB 87.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ----- 256.0/300.4 kB 89.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ----- 256.0/300.4 kB 89.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ----- 256.0/300.4 kB 89.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ----- 256.0/300.4 kB 89.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ----- 256.0/300.4 kB 89.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ----- 256.0/300.4 kB 89.4 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 276.5/300.4 kB 87.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 276.5/300.4 kB 87.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 276.5/300.4 kB 87.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 276.5/300.4 kB 87.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 276.5/300.4 kB 87.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 276.5/300.4 kB 87.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 276.5/300.4 kB 87.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 276.5/300.4 kB 87.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 276.5/300.4 kB 87.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 286.7/300.4 kB 80.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 286.7/300.4 kB 80.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 286.7/300.4 kB 80.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 286.7/300.4 kB 80.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 286.7/300.4 kB 80.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 286.7/300.4 kB 80.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 286.7/300.4 kB 80.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 286.7/300.4 kB 80.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- - 286.7/300.4 kB 80.8 kB/s eta 0:00:01\n",
      "   --------------------------------------- 300.4/300.4 kB 75.8 kB/s eta 0:00:00\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.4.2 pymongo-4.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81584048",
   "metadata": {
    "papermill": {
     "duration": 20.330944,
     "end_time": "2021-07-13T18:05:05.456984",
     "exception": false,
     "start_time": "2021-07-13T18:04:45.126040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# !pip install neattext\n",
    "from keras.models import load_model\n",
    "import neattext.functions as nfx\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as plx\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.layers import Embedding,Dense,LSTM,Bidirectional,GlobalMaxPooling1D,Input,Dropout\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25cd0600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a162fb7",
   "metadata": {
    "papermill": {
     "duration": 4.214542,
     "end_time": "2021-07-13T18:05:09.704601",
     "exception": false,
     "start_time": "2021-07-13T18:05:05.490059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project Idea</th>\n",
       "      <th>Brainstorming Idea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An app for organizing outdoor team-building ac...</td>\n",
       "      <td>Mind Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A website for DIY party decoration ideas</td>\n",
       "      <td>Random Word Association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A platform for virtual reality-based party exp...</td>\n",
       "      <td>Reverse Thinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An AI-powered party planning assistant</td>\n",
       "      <td>Mind Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A social media platform for sharing party play...</td>\n",
       "      <td>Random Word Association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A service for renting themed party decorations</td>\n",
       "      <td>Reverse Thinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An app that generates party game ideas</td>\n",
       "      <td>Mind Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A marketplace for custom-designed party invita...</td>\n",
       "      <td>Random Word Association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A platform for hosting virtual reality parties</td>\n",
       "      <td>Reverse Thinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>An online community for sharing party planning...</td>\n",
       "      <td>Mind Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>An app for creating personalized party playlists</td>\n",
       "      <td>Random Word Association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A subscription service for monthly party supplies</td>\n",
       "      <td>Reverse Thinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>An event planning tool with built-in budget tr...</td>\n",
       "      <td>Mind Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A website for finding unique party venues</td>\n",
       "      <td>Random Word Association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>An AI chatbot for answering party planning que...</td>\n",
       "      <td>Reverse Thinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A mobile app for coordinating potluck parties</td>\n",
       "      <td>Mind Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A platform for renting party equipment and fur...</td>\n",
       "      <td>Random Word Association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A social network for connecting with local par...</td>\n",
       "      <td>Reverse Thinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A website for booking celebrity appearances at...</td>\n",
       "      <td>Mind Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>An app for organizing surprise parties</td>\n",
       "      <td>Mind Mapping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Project Idea       Brainstorming Idea\n",
       "0   An app for organizing outdoor team-building ac...             Mind Mapping\n",
       "1            A website for DIY party decoration ideas  Random Word Association\n",
       "2   A platform for virtual reality-based party exp...         Reverse Thinking\n",
       "3              An AI-powered party planning assistant             Mind Mapping\n",
       "4   A social media platform for sharing party play...  Random Word Association\n",
       "5      A service for renting themed party decorations         Reverse Thinking\n",
       "6              An app that generates party game ideas             Mind Mapping\n",
       "7   A marketplace for custom-designed party invita...  Random Word Association\n",
       "8      A platform for hosting virtual reality parties         Reverse Thinking\n",
       "9   An online community for sharing party planning...             Mind Mapping\n",
       "10   An app for creating personalized party playlists  Random Word Association\n",
       "11  A subscription service for monthly party supplies         Reverse Thinking\n",
       "12  An event planning tool with built-in budget tr...             Mind Mapping\n",
       "13          A website for finding unique party venues  Random Word Association\n",
       "14  An AI chatbot for answering party planning que...         Reverse Thinking\n",
       "15      A mobile app for coordinating potluck parties             Mind Mapping\n",
       "16  A platform for renting party equipment and fur...  Random Word Association\n",
       "17  A social network for connecting with local par...         Reverse Thinking\n",
       "18  A website for booking celebrity appearances at...             Mind Mapping\n",
       "19             An app for organizing surprise parties             Mind Mapping"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('new_data.txt')\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85ce594",
   "metadata": {
    "papermill": {
     "duration": 0.090246,
     "end_time": "2021-07-13T18:05:09.828032",
     "exception": false,
     "start_time": "2021-07-13T18:05:09.737786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brainstorming Idea\n",
       "Mind Mapping               427\n",
       "Random Word Association     13\n",
       "Reverse Thinking            12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Brainstorming Idea'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb52f050",
   "metadata": {
    "papermill": {
     "duration": 0.148726,
     "end_time": "2021-07-13T18:05:10.023963",
     "exception": false,
     "start_time": "2021-07-13T18:05:09.875237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mind Mapping', 'Random Word Association', 'Reverse Thinking'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Brainstorming Idea'].value_counts().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1523d513",
   "metadata": {
    "papermill": {
     "duration": 0.115171,
     "end_time": "2021-07-13T18:05:10.307369",
     "exception": false,
     "start_time": "2021-07-13T18:05:10.192198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data,test_data=train_test_split(data,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ec44fe5",
   "metadata": {
    "papermill": {
     "duration": 0.119297,
     "end_time": "2021-07-13T18:05:10.602970",
     "exception": false,
     "start_time": "2021-07-13T18:05:10.483673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mind Mapping', 'Reverse Thinking', 'Random Word Association'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Brainstorming Idea'].value_counts().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737e3517",
   "metadata": {
    "papermill": {
     "duration": 0.045394,
     "end_time": "2021-07-13T18:05:12.595503",
     "exception": false,
     "start_time": "2021-07-13T18:05:12.550109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text_length=[]\n",
    "    cleaned_text=[]\n",
    "    for sent in tqdm(text):\n",
    "        sent=sent.lower()\n",
    "        sent=nfx.remove_special_characters(sent)\n",
    "        sent=nfx.remove_stopwords(sent)\n",
    "        text_length.append(len(sent.split()))\n",
    "        cleaned_text.append(sent)\n",
    "    return cleaned_text,text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d8c0cb2",
   "metadata": {
    "papermill": {
     "duration": 18.266118,
     "end_time": "2021-07-13T18:05:30.896810",
     "exception": false,
     "start_time": "2021-07-13T18:05:12.630692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 362/362 [00:00<00:00, 90630.82it/s]\n",
      "100%|██████████| 91/91 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "cleaned_train_text,train_text_length=clean_text(train_data[\"Project Idea\"])\n",
    "cleaned_test_text,test_text_length=clean_text(test_data[\"Project Idea\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "544b1735",
   "metadata": {
    "papermill": {
     "duration": 11.666605,
     "end_time": "2021-07-13T18:05:44.490089",
     "exception": false,
     "start_time": "2021-07-13T18:05:32.823484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(cleaned_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04ff6e3e",
   "metadata": {
    "papermill": {
     "duration": 0.384889,
     "end_time": "2021-07-13T18:05:44.974462",
     "exception": false,
     "start_time": "2021-07-13T18:05:44.589573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_freq=pd.DataFrame(tokenizer.word_counts.items(),columns=['word','count']).sort_values(by='count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc26e348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_text_seq=tokenizer.texts_to_sequences(cleaned_train_text)\n",
    "train_text_pad=pad_sequences(train_text_seq,maxlen=100)\n",
    "\n",
    "\n",
    "test_text_seq=tokenizer.texts_to_sequences(cleaned_test_text)\n",
    "test_text_pad=pad_sequences(test_text_seq,maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84ca66a2",
   "metadata": {
    "papermill": {
     "duration": 0.183487,
     "end_time": "2021-07-13T18:05:59.585884",
     "exception": false,
     "start_time": "2021-07-13T18:05:59.402397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lbl_target=LabelEncoder()\n",
    "train_output=lbl_target.fit_transform(train_data['Brainstorming Idea'])\n",
    "test_output=lbl_target.transform(test_data['Brainstorming Idea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd41cd47",
   "metadata": {
    "papermill": {
     "duration": 36.944245,
     "end_time": "2021-07-13T18:06:36.868088",
     "exception": false,
     "start_time": "2021-07-13T18:05:59.923843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('glove.840B.300d.pkl', 'rb') as fp:\n",
    "    glove_embedding = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac8fe60a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.642546,
     "end_time": "2021-07-13T18:06:37.623345",
     "exception": false,
     "start_time": "2021-07-13T18:06:36.980799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "v=len(tokenizer.word_index)\n",
    "embedding_matrix=np.zeros((v+1,300), dtype=float)\n",
    "for word,idx in tokenizer.word_index.items():\n",
    "    embedding_vector=glove_embedding.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[idx]=embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbfaec54",
   "metadata": {
    "papermill": {
     "duration": 0.120284,
     "end_time": "2021-07-13T18:06:37.853558",
     "exception": false,
     "start_time": "2021-07-13T18:06:37.733274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stop=EarlyStopping(patience=5)\n",
    "reducelr=ReduceLROnPlateau(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2963097",
   "metadata": {
    "papermill": {
     "duration": 4.582121,
     "end_time": "2021-07-13T18:06:42.769198",
     "exception": false,
     "start_time": "2021-07-13T18:06:38.187077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, GlobalMaxPooling1D, Dense\n",
    "\n",
    "# Assuming you have 'v' defined as the vocabulary size and 'embedding_matrix' as the pre-trained embedding matrix\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(100,)),\n",
    "    keras.layers.Embedding(v + 1, 300, weights=[embedding_matrix], trainable=False),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.GlobalMaxPooling1D(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax')  # Output layer with 3 units for 3 categories\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.SGD(0.05, momentum=0.09),\n",
    "              loss='sparse_categorical_crossentropy',  # Use sparse_categorical_crossentropy for multi-class classification\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24bca409-df53-41ca-8f7f-b2402a0196c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=' Person A: Create the visually appealing designs for the website.\\nPerson B: Code the functionalities for the website.\\nPerson C: Manage the sales transactions for the website.\\nPerson D: Handle customer inquiries and support on the website.\\nPerson E: Coordinate with the team for any updates or changes to the website.\\n', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a0037-ec09-4ebd-a1ff-586d99d7e8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c5e96-96bd-4481-b9f9-71b06eac7ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98a3bae9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.9818 - accuracy: 0.7266 "
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10172\\1675774447.py\", line 1, in <module>\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n\nReceived a label value of 3 which is outside the valid range of [0, 3).  Label values: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_10242]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m r\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(train_text_pad,train_output,validation_data\u001b[38;5;241m=\u001b[39m(test_text_pad,test_output),\n\u001b[0;32m      2\u001b[0m             epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,callbacks\u001b[38;5;241m=\u001b[39m[early_stop,reducelr],)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10172\\1675774447.py\", line 1, in <module>\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n\nReceived a label value of 3 which is outside the valid range of [0, 3).  Label values: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_10242]"
     ]
    }
   ],
   "source": [
    "r=model.fit(train_text_pad,train_output,validation_data=(test_text_pad,test_output),\n",
    "            epochs=20,batch_size=64,callbacks=[early_stop,reducelr],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdd25f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "suicide_model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af0cae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "suicide_model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d599cdce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1004.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 425ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detectSuicide(text):\n",
    "    cleaned_text, length = clean_text(text)\n",
    "    tokens = tokenizer.texts_to_sequences(cleaned_text)\n",
    "    paded = pad_sequences(tokens,maxlen=50)\n",
    "    if suicide_model.predict([paded]) >=0.50:\n",
    "#         print(\"contains suicidal thoughts\")\n",
    "#         print(suicide_model.predict([paded]))\n",
    "        return 0\n",
    "    else:\n",
    "#         print(\"Doesn't contains suicidal thoughts\")\n",
    "#         print(suicide_model.predict([paded]))\n",
    "        return 1\n",
    "detectSuicide([\"I don't want to live anymore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b423fde7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\shora\\appdata\\roaming\\python\\python39\\site-packages (4.27.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shora\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\shora\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\shora\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb9df68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c7f7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_output[1]\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0577275e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(num_classes=7)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location= torch.device(\"cpu\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ef86bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "text = \"The only reason I haven’t killed myself yet is because of my mom and brothers. If I didn’t have them I’d be dead long ago. \"\n",
    "tokens = bert_tokenizer.encode_plus(\n",
    "    text,\n",
    "    max_length=512,\n",
    "    \n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    padding='max_length',\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',\n",
    ")\n",
    "output = model((tokens['input_ids']), (tokens['attention_mask']))\n",
    "predicted_label = torch.argmax(output, dim=1).item()\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b2bb4d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectSuicide([\"i do not want to live anymore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3eaa9fe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2067087818.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\shora\\AppData\\Local\\Temp\\ipykernel_1412\\2067087818.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    i need help just help me im crying so hard. There is no point living now\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "i need help just help me im crying so hard. There is no point living now\n",
    "I am miserable .My life is over now.\n",
    "The only reason I haven’t killed myself yet is because of my mom and brothers.If I didn’t have them I’d be dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "suicide_model.save(\"model_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4745f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078063a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list= [\"i need helpjust help me im crying so hard\", \"Oh Fuck! can't take this anymore.I am tired of this.\", \"This is it , I can't live anymore.\", \"I am gonna hurt myself\",\n",
    "      \"I do not want to self harm again\", \"It ends tonight.I can’t do it anymore.I quit.\", \"I am endng it .This ends now.\",\n",
    "      \"what would be a painless method of suicide\",\"I want to endmy life\", \"I want to commit suicide\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "app = Flask(__name__)\n",
    "@app.route('/')\n",
    "def hello_world():\n",
    "    return 'Hello, World!'\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06444f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Jan/2024 22:49:55] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Jan/2024 22:49:57] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Jan/2024 22:49:58] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Jan/2024 22:50:02] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "app = Flask(__name__)\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client.serene\n",
    "collection = db.users\n",
    "\n",
    "@app.route('/reg', methods=['POST'])\n",
    "def receive_data():\n",
    "    # data = {\n",
    "    #     'Name': request.form.get('Name'),\n",
    "    #     'Email': request.form.get('Email'),\n",
    "    #     'Number': request.form.get('Number'),\n",
    "    #     'Password': request.form.get('Password')\n",
    "    # }\n",
    "    data = request.get_json()  # Get the JSON data sent from the client\n",
    "    # Process the data\n",
    "    #\n",
    "\n",
    "    result = collection.insert_one(data)\n",
    "    res= {\"data\" : \"hello\"}\n",
    "    return jsonify(res)\n",
    "@app.route('/model', methods=['POST'])\n",
    "def model_data():\n",
    "    # data = {\n",
    "    #     'Name': request.form.get('Name'),\n",
    "    #     'Email': request.form.get('Email'),\n",
    "    #     'Number': request.form.get('Number'),\n",
    "    #     'Password': request.form.get('Password')\n",
    "    # }\n",
    "    data = request.get_json()\n",
    "    id = data['id']\n",
    "    id = str(id)\n",
    "    mail = data['mail']\n",
    "    print(id)\n",
    "    \n",
    "    df = pd.read_csv('pulse.csv')\n",
    "    dff=df['rate']\n",
    "\n",
    "    m = detectSuicide([id])   \n",
    "    for i in dff:\n",
    "        up_doc = collection.find_one_and_update(\n",
    "            {'Email': mail},\n",
    "            {'$push': {'Pulse': i}}\n",
    "        )\n",
    "        \n",
    "    print(m)\n",
    "    if m==1:\n",
    "        text = id\n",
    "        print(text)\n",
    "        tokens = bert_tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        max_length=512,\n",
    "    \n",
    "                        add_special_tokens=True,\n",
    "                        return_token_type_ids=False,\n",
    "                        padding='max_length',\n",
    "                        return_attention_mask=True,\n",
    "                        return_tensors='pt',\n",
    "                    )\n",
    "        output = model((tokens['input_ids']), (tokens['attention_mask']))\n",
    "        m = int(torch.argmax(output, dim=1).item())\n",
    "        m=m+1\n",
    "    \n",
    "    print(m)\n",
    "    print(mail)\n",
    "    # Get the JSON data sent from the client\n",
    "    # Process the data\n",
    "    # insert value into list in MongoDB\n",
    "    updated_doc = collection.find_one_and_update(\n",
    "        {'Email': mail},\n",
    "        {'$push': {'Mood': m}}\n",
    "    )\n",
    "\n",
    "    lst = collection.find_one({'Email': mail })\n",
    "    if lst is not None:\n",
    "        # extract mylist array from document\n",
    "#         mylist = lst['Mood']\n",
    "        json_data = jsonify(m)\n",
    "        return json_data\n",
    "\n",
    "    # res = {\"data\": \"hello\"}\n",
    "    # return jsonify(id)\n",
    "\n",
    "    else:\n",
    "        # return error response if document not found\n",
    "        return jsonify({'error': 'Document not found'})\n",
    "\n",
    "    # Send a JSON response back to the client\n",
    "# Press the green button in the gutter to run the script.\n",
    "\n",
    "@app.route('/login', methods=['POST'])\n",
    "def login_data():\n",
    "    # data = {\n",
    "    #     'Name': request.form.get('Name'),\n",
    "    #     'Email': request.form.get('Email'),\n",
    "    #     'Number': request.form.get('Number'),\n",
    "    #     'Password': request.form.get('Password')\n",
    "    # }\n",
    "    data = request.get_json()\n",
    "    id = data['id']\n",
    "    pas = data['pass']\n",
    "    \n",
    "    # Get the JSON data sent from the client\n",
    "    # Process the data\n",
    "    # insert value into list in MongoDB.\n",
    "    lst = collection.find_one({'Email': id})\n",
    "    if lst is not None:\n",
    "        # extract mylist array from document\n",
    "        checkpass = lst['Password']\n",
    "        if(str(pas)==checkpass):\n",
    "            return jsonify(id)\n",
    "        else:\n",
    "            code={'error' : 'existing user'}\n",
    "            return jsonify(code)\n",
    "    else:\n",
    "        cod = {'error' : 'User doest exists'}\n",
    "        return  jsonify((cod))\n",
    "        # json_data = jsonify(mylist)\n",
    "        # return json_data\n",
    "\n",
    "@app.route('/graph', methods=['POST'])\n",
    "def chart_data():\n",
    "    # data = {\n",
    "    #     'Name': request.form.get('Name'),\n",
    "    #     'Email': request.form.get('Email'),\n",
    "    #     'Number': request.form.get('Number'),\n",
    "    #     'Password': request.form.get('Password')\n",
    "    # }\n",
    "    data = request.get_json()\n",
    "    id1 = data\n",
    "    \n",
    "    # Get the JSON data sent from the client\n",
    "    # Process the data\n",
    "    # insert value into list in MongoDB.\n",
    "    lst = collection.find_one({'Email': id1})\n",
    "    if lst is not None:\n",
    "        # extract mylist array from document\n",
    "        md = lst['Mood']\n",
    "        return jsonify(md)\n",
    "    else:\n",
    "        cod = {'error' : 'User doest exists'}\n",
    "        return  jsonify((cod))        \n",
    "        \n",
    "        \n",
    "@app.route('/')\n",
    "def hello_world():\n",
    "    return 'Hello, World!, wecome to the home page'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ad649f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: deepface in c:\\users\\shora\\appdata\\roaming\\python\\python39\\site-packages (0.0.79)\n",
      "Requirement already satisfied: tensorflow>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from deepface) (2.11.0)\n",
      "Requirement already satisfied: pandas>=0.23.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from deepface) (1.4.4)\n",
      "Requirement already satisfied: keras>=2.2.0 in c:\\users\\shora\\appdata\\roaming\\python\\python39\\site-packages (from deepface) (2.11.0)\n",
      "Requirement already satisfied: mtcnn>=0.1.0 in c:\\users\\shora\\appdata\\roaming\\python\\python39\\site-packages (from deepface) (0.1.1)\n",
      "Requirement already satisfied: fire>=0.4.0 in c:\\users\\shora\\appdata\\roaming\\python\\python39\\site-packages (from deepface) (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from deepface) (1.21.5)\n",
      "Requirement already satisfied: retina-face>=0.0.1 in c:\\users\\shora\\appdata\\roaming\\python\\python39\\site-packages (from deepface) (0.0.13)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from deepface) (9.2.0)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in c:\\programdata\\anaconda3\\lib\\site-packages (from deepface) (4.7.0.72)\n",
      "Requirement already satisfied: Flask>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from deepface) (1.1.2)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from deepface) (4.64.1)\n",
      "Requirement already satisfied: gdown>=3.10.1 in c:\\users\\shora\\appdata\\roaming\\python\\python39\\site-packages (from deepface) (4.7.1)\n",
      "Requirement already satisfied: gunicorn>=20.1.0 in c:\\users\\shora\\appdata\\roaming\\python\\python39\\site-packages (from deepface) (20.1.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from fire>=0.4.0->deepface) (1.16.0)\n",
      "Requirement already satisfied: termcolor in c:\\programdata\\anaconda3\\lib\\site-packages (from fire>=0.4.0->deepface) (2.2.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask>=1.1.2->deepface) (2.0.3)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask>=1.1.2->deepface) (2.11.3)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask>=1.1.2->deepface) (2.0.1)\n",
      "Requirement already satisfied: click>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask>=1.1.2->deepface) (8.0.4)\n",
      "Requirement already satisfied: requests[socks] in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown>=3.10.1->deepface) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown>=3.10.1->deepface) (4.11.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown>=3.10.1->deepface) (3.6.0)\n",
      "Requirement already satisfied: setuptools>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gunicorn>=20.1.0->deepface) (63.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.23.4->deepface) (2022.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=1.9.0->deepface) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (0.31.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (2.11.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (1.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (21.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (2.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (15.0.6.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (1.14.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (4.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (3.19.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (1.51.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.30.0->deepface) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->Flask>=1.1.2->deepface) (2.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (2.16.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (0.4.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=1.9.0->deepface) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bce7c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "app.config['MONGO_URI'] = 'mongodb://localhost:27017/serene'  # MongoDB URI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bec549c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ServerSelectionTimeoutError\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['MONGO_URI'] = 'mongodb://localhost:27017/serene'\n",
    "\n",
    "client = None\n",
    "try:\n",
    "    client = MongoClient(app.config['MONGO_URI'], serverSelectionTimeoutMS=5000)\n",
    "    client.server_info()   # Test the connection\n",
    "    db = client.get_database()\n",
    "    collection = db.get_collection('sangs')\n",
    "    print(\"Connected to MongoDB\")\n",
    "except ServerSelectionTimeoutError:\n",
    "    print(\"Failed to connect to MongoDB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c364bb02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 347.311322,
   "end_time": "2021-07-13T18:10:23.127920",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-13T18:04:35.816598",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
